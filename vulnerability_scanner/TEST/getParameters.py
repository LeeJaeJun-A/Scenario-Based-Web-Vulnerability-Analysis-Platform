import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from fake_useragent import UserAgent

def fetch_site_info(url):
    session = requests.Session()

    # Generate a random User-Agent
    ua = UserAgent()
    headers = {
        "User-Agent": ua.random
    }
    
    try:
        # Perform a GET request to fetch the form
        get_response = session.get(url, headers=headers)
        get_cookies = session.cookies.get_dict()

        # Use BeautifulSoup to parse the HTML and find form fields
        soup = BeautifulSoup(get_response.text, 'html.parser')
        form = soup.find('form')
        
        get_params = {}
        post_params = {}

        if form:
            method = form.get('method', 'get').lower()
            action = form.get('action', url)
            action_url = urljoin(url, action)
            
            for input_tag in form.find_all('input'):
                if input_tag.get('name'):
                    if method == 'get':
                        get_params[input_tag.get('name')] = 'test'
                    else:
                        post_params[input_tag.get('name')] = 'test'

            for select_tag in form.find_all('select'):
                if select_tag.get('name'):
                    options = select_tag.find_all('option')
                    if options:
                        if method == 'get':
                            get_params[select_tag.get('name')] = options[0].get('value', 'test')
                        else:
                            post_params[select_tag.get('name')] = options[0].get('value', 'test')

            # Perform a POST request with the dynamically discovered form fields
            if method == 'post':
                post_response = session.post(action_url, data=post_params, headers=headers)
                post_cookies = session.cookies.get_dict()
            else:
                post_response = None
                post_cookies = get_cookies
        else:
            action_url = url
            post_response = None
            post_cookies = get_cookies

        site_info = {
            'get_response_status_code': get_response.status_code,
            'get_cookies': get_cookies,
            'get_params': get_params,
            'post_response_status_code': post_response.status_code if post_response else None,
            'post_cookies': post_cookies,
            'post_params': post_params,
        }
        
        # Combine GET and POST cookies
        all_cookies = {**get_cookies, **post_cookies}
        
        return {
            'url': action_url,
            'get_parameters': get_params,
            'post_parameters': post_params,
            'cookies': all_cookies
        }
    
    except requests.exceptions.RequestException as e:
        print(f"Error fetching site info: {e}")
        return None

if __name__ == "__main__":
    site_url = "http://127.0.0.1:1399/"
    site_info = fetch_site_info(site_url)
    if site_info:
        print(site_info)
